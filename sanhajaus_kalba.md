# Informacijos Teorija

Egzamino metu bus duota 3 klausimai į kuriuos atsakymas turi būti pateiktas raštu. Egzamino metu niekuo negalima naudotis išskyrus tik savo ranka parašytais konspektais. Jei naudojamasi konspektu tai konspektas turi būti pridedamas prie atsakymų lapo.

Klausimai

- [Informacijos Teorija](#informacijos-teorija)
    - [I Dalis](#i-dalis)
        - [Žmogaus kalbos ir alfabeto raidos istorija. Paskaitos: 1) Origins of written language , 2) History of the alphabet](#%C5%BEmogaus-kalbos-ir-alfabeto-raidos-istorija-paskaitos-1-origins-of-written-language--2-history-of-the-alphabet)
        - [Šaltinio informacijos kodavimas ir vaizdo telegrafo veikimas. Paskaitos: 1) Source encoding 2) Visual telegraphs](#%C5%A1altinio-informacijos-kodavimas-ir-vaizdo-telegrafo-veikimas-paskaitos-1-source-encoding-2-visual-telegraphs)
        - [Elektrostatinio ir elektromagnetinio telegrafo veikimas. Morzės abėcėlė. Paskaitos: 1) Electrostatic telegraphs 2) The battery and electromagnetism 3) Morse code](#elektrostatinio-ir-elektromagnetinio-telegrafo-veikimas-morz%C4%97s-ab%C4%97c%C4%97l%C4%97-paskaitos-1-electrostatic-telegraphs-2-the-battery-and-electromagnetism-3-morse-code)
        - [Simbolių perdavimo greitis ir kanalo talpumas. Paskaitos: 1) Symbol rate 2) Channel capacity](#simboli%C5%B3-perdavimo-greitis-ir-kanalo-talpumas-paskaitos-1-symbol-rate-2-channel-capacity)
        - [Informacijos kiekio pamatavimas. Markovo grandinės. Paskaitos: 1) Measuring information 2) Markov chains](#informacijos-kiekio-pamatavimas-markovo-grandin%C4%97s-paskaitos-1-measuring-information-2-markov-chains)
        - [Informacijos entropija Paskaitos: 1) A mathematical theory of communication 2) Information entropy](#informacijos-entropija-paskaitos-1-a-mathematical-theory-of-communication-2-information-entropy)
        - [Kompresijos kodai ir klaidų korekcija. Paskaitos: 1) Compression codes 2) Error correction](#kompresijos-kodai-ir-klaid%C5%B3-korekcija-paskaitos-1-compression-codes-2-error-correction)
        - [SETI projektas Paskaitos: 1) The search for extraterrestrial intelligence](#seti-projektas-paskaitos-1-the-search-for-extraterrestrial-intelligence)
    - [II Dalis (Skaityti 1-10 skyrius iš knygos)](#ii-dalis-skaityti-1-10-skyrius-i%C5%A1-knygos)
        - [Binarinis simetrinis kanalas ir klaidų korekcijos kodai (Žiūrėti skaidres: Information theory Lect3 v1 )](#binarinis-simetrinis-kanalas-ir-klaid%C5%B3-korekcijos-kodai-%C5%BEi%C5%ABr%C4%97ti-skaidres-information-theory-lect3-v1)
        - [Šaltinio kodavimo teorema . (Žiūrėti skaidres: Information_theory_Lect4_v1)](#%C5%A1altinio-kodavimo-teorema--%C5%BEi%C5%ABr%C4%97ti-skaidres-informationtheorylect4v1)
        - [Simbolių kodai . (Žiūrėti skaidres: Information_theory_Lect4_v1)](#simboli%C5%B3-kodai--%C5%BEi%C5%ABr%C4%97ti-skaidres-informationtheorylect4v1)
        - [Aritmetiniai kodai. (Žiūrėti skaidres: Information_theory_Lect5_v1 )](#aritmetiniai-kodai-%C5%BEi%C5%ABr%C4%97ti-skaidres-informationtheorylect5v1)
        - [LZW kompresijos algoritmas (Žiūrėti skaidres: Information_theory_Lect5_v1 )](#lzw-kompresijos-algoritmas-%C5%BEi%C5%ABr%C4%97ti-skaidres-informationtheorylect5v1)
        - [Kanalo su triukšmu teorema. (Žiūrėti skaidres: Information_theory_Lect6_v1 )](#kanalo-su-triuk%C5%A1mu-teorema-%C5%BEi%C5%ABr%C4%97ti-skaidres-informationtheorylect6v1)
    - [III Dalis](#iii-dalis-skaidr%C4%97s-wikipedia-youtube)
        - [Deterministiniai ir nedeterministiniai baigtiniai automatai](#deterministiniai-ir-nedeterministiniai-baigtiniai-automatai)
        - [Reguliariosios išraiškos](#reguliariosios-išraiškos)
        - [Gramatikos](#gramatikos)
        - [Tiuringo mašina](#tiuringo-mašina)
    - [IV Dalis](#iii-dalis-skaidr%C4%97s-wikipedia-youtube)
        - [Kvantinio kompiuterio veikimas](#kvantinio-kompiuterio-veikimas)
        - [Moderni kriptografija](#moderni-kriptografija)
        - [Bitcoin veikimo sprendimai](#bitcoin-veikimo-sprendimai)

## I Dalis

- **Informacija**. Paprasčiau tariant, informacija yra tai, kas leidžia vienam protui daryti įtaką kitam.
- Informaciją galima išmatuoti ir palyginti naudojant matavimą, vadinamą **entropija**.
- Galime tiksliai apibūdinti, kiek naudodami vienetą, vadinamą **bitu**, netikėtumo matą.
  - Truputis yra susijęs su labai paprasta idėja. **Atsakymas į taip arba ne klausimą**.

### Žmogaus kalbos ir alfabeto raidos istorija.  Paskaitos: 1) Origins of written language , 2) History of the alphabet

- Maždaug prieš **50 000 metų** staiga padaugėjo įvairių kultūros artefaktų, įskaitant muzikos kūrimo instrumentus, naujus įrankius ir kitas kūrybinės raiškos formas.
- Tuo metu visuotinė rašytinė kalba buvo **menas**
  - Mūsų protėviai naudojo natūralias medžiagas, kurdami vaizdinius savo tikrovės vaizdus.
- Dažna šių senovinių paveikslų tema yra **gyvūnų formos, taip pat žmogaus ranka**.
- **Piktogramos** (supaprastintas piešinys, panašus į vaizduojamą fizinį objektą) yra svarbus rašymo raidos žingsnis. (~3 000 m. pr. Kr.)
- **Ideograma** - konceptualus abstrakčios idėjos vaizdas
- **Senovės Mesopotamijoje** yra vieni seniausių kada nors rastų rašytinių dokumentų, kai kurie datuojami iki 3000 m. pr. Kr. 
  - Tai daugelio ankstyviausių pasaulio civilizacijų gimimo vieta.
- **Rebuso principas** - Garsas ir garsas įgauna naują reikšmę (jis neturi nieko bendra su atskirais simboliais)
  - Puikus pavyzdys buvo rastas **Egipte** palei Nilo upę. Datuojamas maždaug 3100 m. pr. Kr., jame yra vieni ankstyviausių kada nors rastų **hieroglifų** užrašų.

---

- Pranešimai formuojami išdėstant simbolius tam tikrais raštais.
- 3000 m. pr. Kr. - Senovės Egiptas - **Hieroglifai** paprastai buvo nesuprantami paprastiems žmonėms (naudojami tik kunigų ir pan.).
    - Simboliai turi dvi kategorijas:
        - žodiniai ženklai - simboliai, vaizduojantys vieną prasmingą sąvoką
        - garso ženklai - šie simboliai žymi garso gabalus.
    - Bendras įvairių dažniausiai naudojamų simbolių skaičius viršijo **1500**
    - Tuo metu simbolių saugojimo priemonė pirmiausia buvo **rokas**. Tokiu būdu perduodant žinutes mobilumas nebuvo pagrindinis rūpestis.
      - Tačiau tuo metu atsirado nauja fizinė terpė simboliams saugoti – **Papirusas**. Ši laikmena puikiai tiko **siunčiant žinutes** didesnėse erdvėse.
    - Tai veda prie kursyvinio scenarijaus, žinomo kaip **Hieratinis**. Šie simboliai buvo pagrįsti hieroglifais, tačiau paveikslėliai buvo supaprastinti, kad atitiktų senovės stenografijos rašymo greitį. Be to, įprastų simbolių skaičius pradėjo mažėti iki maždaug **700**.
    - Žymiai išaugus rašymui ranka, maždaug **650 m. pr. Kr.** atsirado nauja rašymo sistema, vadinama **Demotic**. Dėl naujo paprastumo vaikai gali būti mokomi rašyti **jauname amžiuje**.
      - 3 000 m. pr. Kr. – Mesopotamija – **Anuliraščiu** buvo rašymo sistema, iš pradžių naudota fiskaliniais tikslais
      - Iš pradžių naudojo **šumerai** – daugiau nei **2 000** skirtingų simbolių
    - **Akadų kalba** pamažu pakeitė šumerų kalbą kaip šnekamąją kalbą. Kai akadiečiai jį pritaikė ir pritaikė savo kalbai, simbolių skaičių sumažino iki maždaug **600** ir tai padarė vėl judėdami link garsinių ženklų.
- apie 1700 m. pr. Kr. - Rasti **Sinajus** užrašai
    - Kiekvienas paveikslėlis žymi priebalsį ir nenaudojami žodiniai ženklai.
    - Teisingai skambant, raidės sudarytų žodžius senovės semitų kalboje.
      - 1000 m. pr. Kr. – **Finikiečių abėcėlė** buvo pagrįsta principu, kad vienas ženklas reiškia vieną priebalsį – iš viso **22** simboliai.
    - Simboliai, pasirinkti šiems garsams pavaizduoti, dažnai buvo pasiskolinti iš hieroglifų paveikslėlių, todėl raidės pavadinimas prasidėdavo raidės garsu.
      - Slaptoji galia – jai nereikėjo semitiškos kalbos, kad veiktų. Tai buvo šiandien žinomų graikų, o vėliau ir romėniškų abėcėlės formų šaltinis.

### Šaltinio informacijos kodavimas ir vaizdo telegrafo veikimas. Paskaitos: 1) Source encoding 2) Visual telegraphs

- Turime paprastą kanalą (laidą) - triukšmas leidžia perduoti tik paprasčiausius signalus
- Reikia užkoduoti skaičių, išmestą dviem kauliukais
- Paprasčiausia - tiek signalų, kiek akučių iškrenta
- Kanalo riba (pardavimo greitis) - 2 signalai per sekundę (jei daugiau - sunku suprasti)
- Tam, kad perdavimas būtų efektyvesnis, akučių skaičius surikiuojamas pagal išmetimo tikimybę
- Priskiriamas mažiausias signalų skaičius tikėtiniausiam akučių skaičiui
- Tai - optimaliausias kodavimas tokiam metodui

---

- **signalo gaisras** - vienas skirtumas, dvi būsenos.
  - **Polybijus** buvo graikų istorikas, gimęs 200 m. pr. Signalinės ugnies apribojimas jam buvo aiškus.
  - Gaisro signalas yra puikus, kai galimų pranešimų erdvė yra maža. Tačiau kai pranešimų erdvė, ty bendras galimų pranešimų skaičius, didėja, atsirado poreikis pranešti apie daugybę skirtumų.
- **Aeneas Tacticus**, vienas iš pirmųjų graikų rašytojų apie karo meną IV amžiuje prieš Kristų, sukūrė **lygaus vandens laivo** komunikacijos metodą.
    - Pirmiausia siuntėjas ir gavėjas pakelia žibintuvėlį, kad parodytų pranešimo pradžią
    - Tada siuntėjas nuleidžia deglą ir atidaro savo indą
    - Imtuvas atidaro savo indą, kai mato nuleistą deglą
    - Kai vanduo sustoja, vandens lygis reiškia konkrečią graikų abėcėlės raidę
- **Polibijaus aikštė**, veikia taip:
    - Du žmonės, atskirti atstumu, turi po 10 žibintuvėlių, suskirstytų į dvi grupes po penkis.
    - Norėdami pradėti, siuntėjas pakelia deglą ir laukia, kol gavėjas atsakys. Tada siuntėjas uždega tam tikrą skaičių iš kiekvienos fakelų grupės ir pakelia juos. Tada imtuvas suskaičiuoja pirmoje grupėje uždegtų fakelų skaičių. Šis skaičius apibrėžia eilutės padėtį abėcėlės tinklelyje, kurį jie bendrina. O antroji žibintų grupė reiškia stulpelio padėtį šioje tinklelyje. Eilutės ir stulpelio numerio sankirta apibrėžia išsiųstą laišką.
    - Supraskite, kad pateiktų N taip arba ne klausimų, yra dvi N galimos atsakymų sekos.
- 1605 m. **Francis Bacon** aiškiai paaiškino, kaip ši idėja gali leisti siųsti visas abėcėlės raides naudojant tik vieną skirtumą - **dvišalį šifrą**
    - "Dviejų raidžių perkėlimas penkiomis raidėmis "pakaks 32 skirtumams"
      - 1795 m. – Lordo Džordžo Murėjaus **užrakto telegrafas**
    - Jis buvo sudarytas iš šešių besisukančių langinių, kurios gali būti atidarytos arba uždarytos.
    - Su šešiomis langinėmis turime šešis klausimus, atvirus ar uždarus? Pateikiame du iki šešių arba 64 skirtumų.
    - Su **teleskopu** dabar buvo galima siųsti laiškus neįtikėtinu atstumu tarp švyturių.

### Elektrostatinio ir elektromagnetinio telegrafo veikimas. Morzės abėcėlė. Paskaitos: 1) Electrostatic telegraphs 2) The battery and electromagnetism 3) Morse code

– 600 m. pr. Kr. – Talis iš Mileto, plačiai laikomas pirmuoju graikų filosofu, atranda, kad gintaras pritraukia mažas daleles, kai trinamas į kailį.
– Benjaminas Franklinas, kuris 1752 metais siekė įrodyti, kad yra ryšys tarp žaibo ir šių mažyčių smūgių dėl trinties.
- Atlikdamas garsiai pavojingą eksperimentą vienas su sūnumi, jis įleido aitvarą į perkūniją ir netoli dugno, kur siūlas buvo šlapias, surišo geležinį raktą ir po kurio laiko prikėlė savo snukį prie rakto, patyrė seriją maži smūgiai, identiški susilietus su kailiu sukeliamiems smūgiams.
– Nustatyta, kad laidininkai, tokie kaip varinė viela, šį traukimo efektą perduos per atstumą.
- 1774 m. prancūzų išradėjas George'as Louisas Le Sage'as išsiuntė pranešimus per 26 laidų masyvą, kiekvienas laidas reiškia abėcėlės raidę. Kai viename gale įvyksta iškrova, šerdies rutulys judės kitame. Šio telegrafo bėda buvo ta, kad jis tęsėsi tik tarp dviejų jo namo kambarių. Įlinkio galia buvo maža ir su ja dirbti buvo sunku.
- Alessandro Volta išrado Leyden jar kondensatorių arba įkrovos saugojimo įrenginį. Ir sujungęs daugybę stiklainių, jis pastebėjo, kad gali dar labiau padidinti talpą ir išleisti mirtiną elektros voltą.
- Per ateinančius 50 metų žmonės bandė kurti sistemas, skirtas kibirkštims siųsti didesniais atstumais, naudojant ilgesnius laidus ir galingesnes iškrovas. Tačiau elektrostatinių iškrovų siuntimas kaip ryšio būdas atrodė gremėzdiškas archajiškas ir nepagerėjo, palyginti su esamu to meto optiniu telegrafu.

---

- Paimkite du metalo gabalus: **vario** ir **cinko**, kuriuos prijungiate prie laidžių laidų, tada panardinkite metalus į **elektrolitą** (šiuo atveju actą).
- XVIII amžiaus pabaigoje **Alessandro Volta** išsiaiškino, kad sujungus šias ląsteles, šis krūvio srautas sustiprėtų.
- Iki 1800 m. jis viską supaprastino dar labiau pašalindamas stiklainį, kuriame buvo daugiau elektrolito, nei iš tikrųjų reikėjo, - pakeisdamas jį plona kempinėle, įmirkyta elektrolitu. Tokios paprastos ląstelės gali būti sukrautos viena ant kitos.
- **Voltaic pile**, pirmasis akumuliatorius istorijoje, užtikrinantis nuolatinį elektros krūvio arba srovės srautą.
- **Bubble Telegraph** apėmė 26 skirtingas grandines, po vieną kiekvienai raidei, ir buvo pagrįsta tuo, kad srovę teikianti baterija gali būti dedama toliau nuo vandens indelių, kuriuose yra burbuliukus sukuriančių laidų. Ši sistema niekada nebuvo priimta.
- 1819 m. buvo nustatyta, kad jei mes tiesiog praeiname laidą šalia kompaso ir prijungiame prie baterijos, kai tik laidas susisiekia su baterija, adata pašoko be jokio fizinio kontakto.
- Iki 1824 m. William Sturgeon pademonstravo būdą, kaip dar labiau padidinti šio lauko stiprumą, tiesiog apvyniodamas vielos ritę aplink geležies gabalą, pavyzdžiui, vinį.
- Staiga buvo įmanoma sukurti magnetinius laukus, kurie galėtų tiksliai ir jėga judinti adatas naudojant elektros srovę, tiekiamą per atstumą, naudojant ilgą vielos kilpą ir stiprią bateriją.

---

– 1832 m. matematikas Carlas Gaussas ir fizikos profesorius Williamas Weberis sujungė savo observatoriją su laboratorija naudodami **galvanometrą**
- Viename gale prijungtas jungiklis pakeistų elektros srovę dviem kryptimis
- Kitame gale galvanometras pasisuko į kairę arba į dešinę pagal elektros srovės kryptį
- Tokia sistema turėjo dvi būsenas: **kairė** arba **dešinė** įlinkis
- Jie priskyrė trumpesnius simbolius dažniausiai vartojamoms abėcėlės raidėms (pvz., A – vienas posūkis į dešinę ir E – vienas posūkis į kairę) ir ilgesnius simbolius rečiau vartojamoms raidėms (pvz., K – trys posūkiai į dešinę).
- Tačiau signalizacijos greitis buvo lėtas dėl adatos judesių (maks. 1 nukreipimas per sekundę)
- 1848 m. 20 simbolių siuntimas buvo vienos savaitės atlyginimas parduotuvės savininkui (per brangu)
- **Samuelis Morse**, bendradarbiaudamas su Albertu Vailu, išrado spyruoklinio krautuvo svirtį (raktą)
    - Priėmimo gale buvo spyruoklinė svirtis, kuri elektromagneto pagalba skleidė spragtelėjimus
    - Morzė pakeitė klavišo paspaudimo trukmę:
        - **Taškas** - trumpas klavišo paspaudimas
          - **Brūkšnelis** – 3 kartus ilgesnis už tašką
    - Schema priskyrė trumpesnes raidžių sekas įprastesnėms raidėms (pagal knygas)
    - Po raidės sistema įterpia 3 taškų pauzę
- Dėl šios raktų sistemos paprastumo ji tapo daug greitesnė nei bet koks adatinis telegrafas
- Iki 1900 m. vienos žinutės kaina sumažėjo iki 30 centų už pranešimą
- Vėliau buvo išrastos kodų knygos, kurios pavienius žodžius susiejo su vyzdžiais, o tai dar labiau sumažino išlaidas
    - "Blade" reiškia "Prašome pavadinti ir rezervuoti sau ir šeimai šias būstas"

### Simbolių perdavimo greitis ir kanalo talpumas. Paskaitos: 1) Symbol rate   2) Channel capacity

– Pirminiai simboliai – raidės
– Antriniai simboliai – (Morzės kodo signalai) žemesnio lygio signalizacijos įvykiai, pvz., elektros impulsai
- Baudot Multiplex sistema (1874) susideda iš 5 klavišų, kuriuos buvo galima groti bet kokia kombinacija. Kodas kiekvienai abėcėlės raidei priskyrė 32 skirtingus akordus su likučiais, naudojamais vežimo grąžinimui, nauja eilute ir tarpais.
- Jambinis skaitiklis, mechaniniai sistemos nervai, pakeičia žodžius į skylutes juostoje, o juostoje esančias skyles į elektros impulsus, sklindančius per laidus.
- Perdavimo greitį fiziškai ribojo **minimalūs tarpai** tarp šių impulsų arba pulso dažnis.
    - Per greitai siunčiami impulsai, todėl atsiranda **tarp simbolių trukdžių**.
- **simbolių dažnis** yra signalizacijos įvykių, kuriuos galima suspausti per vieną sekundę, skaičius

---

– Buvo dar vienas būdas padidinti ryšio sistemos pajėgumą – Galime padidinti įvairių signalizacijos įvykių skaičių.
– Tai buvo Thomaso Edisono įgyvendinta idėja, kurią jis pritaikė Morzės kodo sistemai, ir ji buvo pagrįsta mintimi, kad naudojant silpnas ir stiprias baterijas galima generuoti skirtingo stiprumo signalus. Jis taip pat naudojo dvi kryptis, kaip darė Gaussas ir Weberis, pirmyn ir atbulinės eigos srovę ir du intensyvumus. Taigi jis turėjo plius tris voltus, plius vieną voltą, minus vieną voltą ir minus tris voltus. Keturios skirtingos srovės vertės, kurias galima keisti.
- Keturkampis telegrafas naudojo tokią sistemą ir buvo naudojamas iki XX a.
- Smulkūs skirtumai sukelia sunkumų priėmimo pusėje.
- Ryšio sistemos pajėgumą galima apibrėžti naudojant šias dvi labai paprastas idėjas:
  - Pirma, kiek simbolių perdavimo per sekundę? Tai pavadinome **simbolių greičiu**. Ir šiandien jis žinomas tiesiog kaip **baud**, Emilio Baudot vardu.
  - Antra, kiek skirtumų vienam simboliui? Kurį galime įsivaizduoti kaip **simbolių erdvę**. Ir mes galime tai pavadinti **s**.
- Po **n** simbolių turime medį su** s^n** lapais.
- **Pranešimo vieta** yra tiesiog vieno iš šių medžių **pagrindo** plotis. Jis apibrėžia bendrą galimų pranešimų, kuriuos galima išsiųsti, skaičių n simbolių seka.
- Tam tikro kanalo **Kanalo talpa** yra didžiausias informacijos greitis (informacijos vienetais per laiko vienetą), kurį galima pasiekti su savavališkai maža klaidos tikimybe.

### Informacijos kiekio pamatavimas. Markovo grandinės. Paskaitos: 1) Measuring information  2)  Markov chains

- Informacijos matavimas grindžiamas **minimaliu klausimų skaičiumi**, kad būtų galima apibrėžti pranešimą arba sprendimų medžio aukštį, o kadangi jis dažniausiai perduodamas dvejetainiais skaitmenimis, galime jį sutrumpinti ir savo padalinį pavadinti **bitu*. *, vietoj dvejetainio skaitmens.
    - Jis apskaičiuojamas kaip galimų simbolių sekų skaičiaus logaritmas.
    - 10 monetų vartymui reikia 10 bitų, šešių raidžių žodžiui reikia 28,2 bitų, o pokerio kortai – 28,5 bitų.
- 1928 m. Ralphas Hartley, kuris rėmėsi Harry Nyquist (Bell Labs) idėjomis, paskelbė svarbų dokumentą pavadinimu „Informacijos perdavimas“:
    - Informacija = H, nes H lygus N kartų S logaritmui, kur:
        - H yra mūsų informacija
        - N yra simbolių skaičius pranešime
        - S yra skirtingų simbolių, galimų kiekvieno pasirinkimo metu, skaičius
    - Tai taip pat gali būti parašyta kaip H = log(S^N)
- Taigi, **informacija** yra **pranešimo erdvės logaritmas**

---

- **Bernoulli** proved that the expected value of simple statistical observations will converge on the actual ratio as the number of trials increases, known as the **weak law of large numbers**.
- **Francis Galton's bean machine** visualizes a **binomial distribution**, which appears to be an ideal form as it kept appearing everywhere any time you looked at the variation of a large number of random trials.
- Pavel Nekrasov, originally a theologian by training, didn't like the idea of us having this predetermined statistical fate. He made a famous claim that **independence** is a necessary condition for the law of large numbers
- This claim angered another Russian mathematician, **Andrey Markov**
- Markov extends Bernoulli's results to dependent variables using an ingenious construction - **Markov state machine**.
- Markov proved that as long as every state in the machine is reachable, when you run these machines in a sequence, they reach equilibrium.
- The concept of modeling sequences of random events using states and transitions between states became known as a **Markov chain**.

![Markov Chain](https://bookdown.org/probability/beta/MC1.png)

### Informacijos entropija Paskaitos: 1) A mathematical theory of communication 2)   Information entropy

- 1949 m. **Shannon** naudojo Markovo modelius kaip pagrindą, kaip mes galime galvoti apie bendravimą:
    - Įsivaizduokite tekstą, parašytą raidėmis A, B ir C. Pastebite, kad As, atrodo, susilieja, o B ir C – ne.
    - **0-osios eilės** apytikslis nustatymas – atsitiktinai pasirinkite kiekvieną simbolį A, B arba C
    - **1 eilės** aproksimacija, kai raidės parenkamos savarankiškai, bet pagal kiekvienos raidės tikimybę pradinėje sekoje.
    - **2-osios eilės** apytikslis skaičiavimas atsižvelgia į kiekvieną **porą** raidžių, kurios gali atsirasti.
        - Pradedame bet kur ir pasirenkame plytelę, o išvestį užrašome pirmąją raidę
          – Tada pereiname prie taurės, apibrėžtos antra raide. Mes pasirenkame naują plytelę ir kartojame šį procesą neribotą laiką
        - Atkreipkite dėmesį, kad ši seka pradeda atrodyti labai panaši į pradinį pranešimą, nes šis modelis fiksuoja sąlygines priklausomybes tarp raidžių.
    - Jei norėtume padaryti dar geriau, galėtume pereiti prie **3-osios eilės** apytikslės, kuri atsižvelgia į trijų raidžių grupes arba „**trigramas**“.
      – Toliau Šenonas taiko tą pačią logiką tikram **angliškam** tekstui, naudodamas statistiką, kuri buvo žinoma dėl raidžių, porų, trigramų ir kt.
    - Jis rodo **tą pačią eigą** nuo nulinės eilės atsitiktinių raidžių iki pirmos, antros eilės ir trečios eilės sekų.
    - Tada jis tęsia ir bando tą patį, naudodamas **žodžius, o ne raides**
      – Panašumas į įprastą anglišką tekstą „gana pastebimai didėja kiekviename gylyje“.

---

- **Claude'as Shannonas** vidutinės neapibrėžties matą vadina „entropija“, o jam pavaizduoti naudoja raidę H.
- Šenono pasirinktas entropijos vienetas yra pagrįstas sąžiningo monetos metimo neapibrėžtumu, ir jis tai vadina „** bitu**“, kuris prilygsta sąžiningam atšokimui.
- Entropija arba H yra to simbolio **tikimybės**, padaugintos iš **logaritmo** pagrindo du iš vieno, sumavimas **kiekvienam simboliui**, palyginti su to simbolio tikimybe.
- Entropija yra **maksimali**, kai visi rezultatai yra **vienodai tikėtini**.
- Pagrindinė idėja yra ta, kad jei informacijos šaltinio entropija krenta, tai reiškia, kad galime užduoti mažiau klausimų, kad atspėtų rezultatą.

![Entropy](https://computersciencesource.files.wordpress.com/2010/01/entropycalc1.png)

### Kompresijos kodai ir klaidų korekcija. Paskaitos: 1) Compression codes 2) Error correction

- Kai informaciją, pavyzdžiui, vaizdą, pavaizduojame skaitmeniniu būdu, tai reiškia, kad turime ją suskaidyti į mažus gabalėlius. Tai leidžia mums siųsti vaizdą kaip spalvų simbolių seką, o šios spalvos gali būti pavaizduotos kaip unikalūs skaičiai, naudojant tam tikrą kodą.
  - **Davidas Huffmanas** garsiai pateikė optimalią strategiją, kurią paskelbė 1952 m., remiantis dvejetainio medžio kūrimu iš apačios į viršų. **Huffmano kodavimas:**
    - Pirmiausia išvardykite visus simbolius apačioje (mazgai).
    - Tada randame du mažiausiai tikėtinus mazgus, šiuo atveju B ir C, ir sujungiame juos į vieną ir sudedame tikimybes.
    - Pakartokite su kitais dviem mažiausiai tikėtinais mazgais ir tęskite sujungimą, kol viršuje atsiras vienas mazgas.
    - Galiausiai šio medžio kraštus bet kokia tvarka pažymime 0 arba 1.
    - Kiekvienos raidės kodas yra tik kelias nuo medžio viršūnės iki nurodytos raidės.
- Claude'as Shannonas pirmasis teigė, kad **glaudinimo riba** visada bus pranešimo šaltinio **entropija**.
  - Mažėjant entropijai, didėja gebėjimas suspausti

![Huffman Coding](https://i.stack.imgur.com/9T1Am.png)

---

- 1940-aisiais **Richard Hamming** sukūrė metodą, kuris galėtų automatiškai aptikti ir ištaisyti vieno bito klaidas, nepertraukiant skaičiavimų.
- **Pariteto bitas** yra vienas bitas, pridedamas prie pranešimo pabaigos ir nurodo, ar **vienetų** skaičius pranešime yra **lyginis ar nelyginis**.
    - Jei įvyksta viena klaida, imtuvas gali ją aptikti, nes pariteto bitas nebeatitinka. Tačiau norint aptikti ir ištaisyti pavienes klaidas, Hamingas turėjo pridėti daugiau pariteto bitų, kad nustatytų klaidos vietą. Tai veda prie jo **septynių keturių kodo**, kuris prideda tris pariteto bitus prie kiekvieno keturių duomenų bitų bloko taip:
        - Pirmiausia pradedame nuo **trijų pariteto bitų**, kuriuos galima pavaizduoti apskritimu.
          - **keturi duomenų bitai** įdedami į šiuos regionus tam tikra tvarka.
        - Norėdami apskaičiuoti pariteto bitus, mes žiūrime į kiekvieną apskritimą po vieną, kiekviename yra trys duomenų bitai.
    - Ši sistema gali automatiškai ištaisyti pavienes klaidas pagal paprastą taisyklę: jei įvyksta viena klaida, du ar daugiau pariteto bitų bus neteisingi ir kur jie susikerta, yra klaidos vieta.
- Visi klaidų taisymo kodai šiek tiek padidina šaltinio pranešimų dydį, o tai automatiškai ištaiso klaidas.
  – Claude'as **Shannonas** panaudojo šią atleidimo idėją, kad iš naujo apibrėžtų ryšio kanalo pajėgumą, nes didėjant jūsų kanalo triukšmui, turime padidinti pertekliaus kiekį, kad galėtume bendrauti be klaidų. Tai turi sumažinti efektyvų informacijos kiekį, kurį galite siųsti per laiko vienetą.

![Hamming Code](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Hamming%287%2C4%29.svg/320px-Hamming%287%2C4%29.svg.png)

### SETI projektas Paskaitos: 1) The search for extraterrestrial intelligence

- Šiuolaikinės nežemiško intelekto, arba **SETI**, paieškos prasidėjo 1959 m. su dviem Kornelio fizikais Giuseppi Cocconi ir Philipu Morrisonu.
- Tyrėjai mano, kad bet kuri protinga civilizacija bus atradusi galimybę **perduoti radijo bangas**.
  – Pirmajame SETI susitikime 1961 m. Johnas Lilly pasiūlė mokslininkams studijuoti **delfinų kalbas**, kad padėtų jiems daugiau sužinoti apie tai, kokie gali būti nežemiški signalai.
- Zipf įstatymas:
    - Iš pradžių, kai žmonių **kūdikiai** išmoksta kalbėti, sklindantys garsai yra daugiau ar mažiau atsitiktiniai arba nestruktūruoti. (Plokštas nuolydis diagramoje)
      - Tačiau vaikams mokantis savo tėvų kalbos, mūsų kalbos modeliams primetama **struktūra**.
    - Jei pavaizduotume visus garsus pagal jų pasirodymą, šio grafiko nuolydis susilieja į 45 laipsnių kampą arba **-1 nuolydį** log-log diagramoje.
    - Įdomu tai, kad tas pats nuolydis pasirodo **skirtingomis žmonių kalbomis** ir atrodo, kad tai yra visiems žmonėms būdingas modelis.
    - Dar labiau stebina tai, kad šis modelis taip pat atsirado studijuojant **delfinų** bendravimą.
- Doyle'as ir McCowanas apskaičiavo **skirtingo gylio** arba eilės entropiją, todėl pavieniai žodžiai yra pirmosios eilės, dviejų žodžių grupės yra antros eilės, trijų žodžių grupės yra trečios eilės ir pan. Tada jie nubraižė informacijos entropijos vertę šio gylio atžvilgiu. Suaugusiems žmonėms, kaip galime tikėtis, jie nustatė, kad **informacijos entropija mažėja didėjant gyliui**.
  – Nuostabu, kad Doyle'as ir McCowanas padarė tą patį su **delfinų** kalbomis ir **rado tą patį modelį**.
- Kaip sako Doyle'as, jei gauname **siauros juostos signalą**, **-1 nuolydį Zipf diagramoje** ir **aukštesnio laipsnio Šenono entropijas**, tai įveikėme (rasime ET ryšį )

## II Dalis (Skaityti 1-10 skyrius iš knygos)

### Binarinis simetrinis kanalas ir klaidų korekcijos kodai (Žiūrėti skaidres: Information theory Lect3 v1  )

- Tikimybių teorijoje ir statistikoje **binominis skirstinys** su parametrais n ir p yra diskretus tikimybių pasiskirstymas, kai pasisekė n nepriklausomų eksperimentų sekoje, kurių kiekvienas užduoda klausimą „taip–ne“ ir kiekvienas turi savo Būlio vertės rezultatas: atsitiktinis kintamasis, turintis vieną informacijos bitą: sėkmė/taip/teisinga/vienas (su tikimybe p) arba nesėkmė/ne/klaidinga/nulis (su tikimybe q = 1 − p).    - ![Binomial Distribution](https://wikimedia.org/api/rest_v1/media/math/render/svg/b872c2c7bfaa26b16e8a82beaf72061b48daaf8e)
    - Binomial Coefficient: ![Binomial Coefficient](https://wikimedia.org/api/rest_v1/media/math/render/svg/d33401621fb832dd2f9783e80a906d562f669008)
    - Mean (Expected value of X): ![Mean](https://wikimedia.org/api/rest_v1/media/math/render/svg/3f16b365410a1b23b5592c53d3ae6354f1a79aff)
    - Variance (deviation): ![Variance](https://wikimedia.org/api/rest_v1/media/math/render/svg/bf5b4b6e591c413e746d1ba867277e99b9b083b9)
- **dvejetainis simetriškas kanalas** (arba BSC) yra bendras ryšio kanalo modelis, naudojamas kodavimo teorijoje ir informacijos teorijoje. Šiame modelyje siųstuvas nori išsiųsti bitą (**nulis arba vienetas**), o imtuvas gauna bitą. Daroma prielaida, kad bitas paprastai perduodamas teisingai, tačiau jis bus „apverstas“ su maža **tikimybe** („kryžminio tikimybe“). Šis kanalas dažnai naudojamas informacijos teorijoje, nes tai vienas paprasčiausių analizuojamų kanalų.    - ![Channel](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Binary_symmetric_channel_%28en%29.svg/1200px-Binary_symmetric_channel_%28en%29.svg.png)
    - Conditional Probabilities: ![Conditional Probabilities](https://wikimedia.org/api/rest_v1/media/math/render/svg/729fb9668be91ed00a76c0c0692425e24035648f)

---

- Error correcting codes:
    - **R^n** - repetition code - each symbol repeated n times
    - **R^3** - each symbol repeated 3 times - P(s≠s^)=3f^2(1 - f) + f^3 = 3f^2 - 2f^3 (≈ 0.03 with f = 0.1)
    - **Hamming Code**
- **Šenono triukšmingo kanalo kodavimo teorema** nustato, kad esant bet kokiam ryšio kanalo triukšmo užterštumo laipsniui, galima perduoti atskirus duomenis (skaitmeninę informaciją) **beveik be klaidų** iki **apskaičiuojamo didžiausia norma** per kanalą. Šį rezultatą 1948 m. pristatė Claude'as Shannonas ir iš dalies buvo pagrįstas ankstesniais Harry Nyquist ir Ralph Hartley darbais ir idėjomis.
![Shannon](http://www.inference.org.uk/itprnn/1997/l1/img72.gif)

### Šaltinio kodavimo teorema . (Žiūrėti skaidres: Information_theory_Lect4_v1)

- **Šenono šaltinio kodavimo teorema** (arba be triukšmo kodavimo teorema) nustato galimo duomenų suspaudimo ribas ir Šenono entropijos operatyvinę reikšmę.
- Šaltinio kodavimo teorema rodo, kad (riboje, kadangi nepriklausomų ir identiškai paskirstytų atsitiktinių kintamųjų (iid) duomenų srauto ilgis linkęs į begalybę), neįmanoma suspausti duomenų taip, kad kodo sparta (vidutinis skaičius bitai vienam simboliui) yra mažesnis už šaltinio Šenono entropiją, tačiau nėra beveik tikras, kad informacija bus prarasta. Tačiau galima gauti kodo greitį **savavališkai artimą Šenono entropijai**, su nereikšminga praradimo tikimybe.
- Informacijos entropija – tai vidutinis greitis, kuriuo informaciją sukuria stochastinis duomenų šaltinis.
- Informacijos entropijos matas, susietas su kiekviena galima duomenų reikšme, yra neigiamas reikšmės tikimybės masės funkcijos logaritmas:

![Shannon's Entropy](https://wikimedia.org/api/rest_v1/media/math/render/svg/f96cf5194b9102f383a05c04c8994e7af8b161fb)

### Simbolių kodai . (Žiūrėti skaidres: Information_theory_Lect4_v1)

- Garantuojama, kad **simbolių kodai** bus suspausti ir išskleisti be klaidų; tačiau yra tikimybė, kad kodai kartais gali sukurti užkoduotas eilutes, ilgesnes nei pradinė šaltinio eilutė.
- Idėja yra ta, kad galime pasiekti suglaudinimą vidutiniškai priskirdami trumpesnes koduotes labiau tikėtiniems rezultatams ir ilgesnes koduotes mažiau tikėtiniems rezultatams.
    - **Kodinio žodžio prekybos centras**
- Simbolio kodas vadinamas **priešdėlio kodu**, jei joks kodo žodis nėra kito kodinio žodžio priešdėlis.
    - **Huffmano kodavimas**

### Aritmetiniai kodai. (Žiūrėti skaidres:  Information_theory_Lect5_v1 )

- Simboliniai kodai prastai veikia, jei viena tikimybė yra didelė, o visos kitos mažos. Tai išsprendžia aritmetinis kodas (Bet jis nėra vienintelis sprendimo būdas).
- Bet kokį duomenį galima aprašyti kaip **intervalą tarp dviejų skaičių**, kurie yra tarp 0 ir 1.
- Jei turim simbolius su tikimybėm, juos galim paverst į intervalus. Tarkim, tikimybes:
    - P(x=a) = 0.25,
    - P(x=b) = 0.25,
    - P(x=c) = 0.5,
- Pagal ittervalus:
    - a [0, 0.25],
    - b [0.25, 0.5],
    - c [0.5, 1]
- Pvz., turint a,b,c intervalus galime suformuoti žinutę - cca. cca intervalas bus [0.75, 0.8125]
    - Gavus intervalą jį galima įstatyti į šitą grafą ir iš jo gaunam, binarinį kodą - 1100.

### LZW kompresijos algoritmas (Žiūrėti skaidres:  Information_theory_Lect5_v1 )

- **Lempel–Ziv–Welch (LZW)** yra universalus be nuostolių duomenų glaudinimo algoritmas, sukurtas Abrahamo Lempelio, Jacobo Zivo ir Terry Welcho.
    - LZW glaudinimas naudoja kodų lentelę su 4096 kaip įprastas lentelės įrašų skaičiaus pasirinkimas. Kodai nuo 0 iki 255 kodų lentelėje visada priskiriami **pavieniams baitam** iš įvesties failo.
    - Kai prasideda kodavimas, kodų lentelėje yra tik pirmieji 256 įrašai, o likusi lentelės dalis yra **tuščiai**. Suspaudimas pasiekiamas naudojant kodus nuo 256 iki 4095 baitų sekoms pavaizduoti.
    - Tęsiant kodavimą, LZW **identifikuoja pasikartojančias sekas** duomenyse ir **prideda** jas į kodų lentelę.
    - Dekodavimas pasiekiamas paimant kiekvieną kodą iš suspausto failo ir išverčiant jį per kodų lentelę, kad **rastumėte**, kokį simbolį ar simbolius jis reiškia.

Encoding:

```none
  *     PSEUDOCODE
  1     Initialize table with single character strings
  2     P = first input character
  3     WHILE not end of input stream
  4          C = next input character
  5          IF P + C is in the string table
  6            P = P + C
  7          ELSE
  8            output the code for P
  9          add P + C to the string table
  10           P = C
  11         END WHILE
  12    output code for P 
```

Decoding:

```none
*    PSEUDOCODE
1    Initialize table with single character strings
2    OLD = first input code
3    output translation of OLD
4    WHILE not end of input stream
5        NEW = next input code
6        IF NEW is not in the string table
7               S = translation of OLD
8               S = S + C
9       ELSE
10              S = translation of NEW
11       output S
12       C = first character of S
13       OLD + C to the string table
14       OLD = NEW
15   END WHILE
```

### Kanalo su triukšmu teorema. (Žiūrėti skaidres: Information_theory_Lect6_v1 )

- Bet koks fizinis duomenų perdavimo kanalas negali būti 100% patikimas. Pagal Shannon’ą  galima naudoti ir nepatikima kanalą su dideliu triukšmu ir perduoti informacija patikimu būdu, t.y. nieko neprarasti. Tad reikėtų ne stengtis atrasti kuo švaresnį duomenų perdavimo būdą (didinant stiprumą - tai kainuoja ir dažniausiai neapsimoka\neįmanoma), o **optimizuoti** kodavimo ir dekodavimo algoritmus.

## III Dalis

### Deterministiniai ir nedeterministiniai baigtiniai automatai

- Automatai yra abstrakčios mašinos, turinčios baigtinį būsenų rinkinį. Atsižvelgiant į tam tikrą įvestį, jie pereina iš būsenos į būseną. Galite galvoti apie juos kaip apie struktūrines schemas.

- NFA yra nedeterministinis baigtinis automatas. Nedeterministinė reiškia, kad jis gali pereiti į kelias būsenas ir būti jose vienu metu (t. y. kai kuriai įvesties įvestis).

- DFA yra deterministinis baigtinis automatas. Deterministinis reiškia, kad jis vienu metu gali būti ir pereiti tik į vieną būseną (t. y. tam tikroje įvestyje).

– Pagrindinis svarbus skirtumas yra tas, kad NFA paprastai yra daug efektyvesnė.

### Reguliariosios išraiškos

– Reguliari išraiška (sutrumpinta kaip reguliarioji išraiška arba reguliarioji išraiška; taip pat vadinama racionalia išraiška) yra simbolių seka, nurodanti paieškos šabloną tekste.
- Paprastai tokius modelius naudoja eilučių paieškos algoritmai, atliekantys operacijas „rasti“ arba „rasti ir pakeisti“ arba įvesties patvirtinimui.
- Tai teorinės informatikos ir formaliosios kalbos teorijos sukurta technika.

### Gramatikos

- Kontekstinė gramatika yra formali gramatika, kuri naudojama generuoti visas įmanomas eilutes tam tikra oficialia kalba.
- Kontekstinė gramatika G gali būti apibrėžta keturiomis eilutėmis kaip G= (V, T, P, S)
- Kur:
    - G apibūdina gramatiką
    - T apibūdina baigtinį galinių simbolių rinkinį.
    - V apibūdina baigtinį negalinių simbolių rinkinį
    - P apibūdina gamybos taisyklių rinkinį
    - S yra pradžios simbolis.
- CFG eilutėje išvesti naudojamas pradžios simbolis. Galite išvesti eilutę pakartotinai pakeisdami ne terminalą dešinėje produkcijos pusėje, kol visi ne terminalai bus pakeisti terminalo simboliais.

### Tiuringo mašina

- Tiuringo mašinos, kurias pirmą kartą aprašė Alanas Turingas, yra paprasti abstraktūs skaičiavimo įrenginiai, skirti padėti ištirti, kiek ir ką galima apskaičiuoti.
- Turingo „automatinės mašinos“ buvo specialiai sukurtos tikriems skaičiams apskaičiuoti.
- Šiandien jie laikomi vienu iš pamatinių skaičiavimo ir (teorinių) informatikos modelių.

## IV Dalis

### Kvantinio kompiuterio veikimas

- Kvantiniai kompiuteriai naudoja qbitus.
- **Qbitas** (Kubitas) – kintanti kvantinė būsena.
- Kubitas yra pagrindinė varomoji galia kvantinio kompiuterio. Kubitas gali saugoti dvi reikšmės 1 arba 0 arba jų superpoziciją.
- **Superpozicija** – kvantas esantis superpozicijoje turėti dvi reikšmes vienu metu. Šito neturi klasikinė fizika.

### Moderni kriptografija

- **Kriptografija** – mokslas, tiriantis informacijos užšifravimo ir iššifravimo metodus. Kriptografija yra sudėtinė kriptologijos mokslo dalis.
- Privalumai:
    - Konfidencialumas – informacijos apsauga nuo neautorizuoto priėjimo.
    - Autentifikacija – tam tikros technikos užtikrina, kad informacija yra tikra ir nesuklastota.
    - Nepažeistumas – tam tikri algoritmai užtikrina, kad duomenys nebūtų pažeisti ir vientysi.
- Minusai:
    - Sudėtinga pasiekti netgi vartojui.
    - Kriptografija išnaudoja nemažai laiko ir pinigų. Dėl reikalingų perskaičiavimų, daugiau laiko prireikia.
    - Gerą kriptografijos būdą implementuoti yra sudėtinga.
- Kvantinė kriptografija skiriasi nuo paprastos kriptografijos tuo, kad paprasta kriptografija remiasi matematika, o kvantinė – fizika.
- Kvantinėj kriptografijoj, raktai yra sudėti iš fotonų. Kvantinė kriptografijoje fotonai gali būti keletoj fazių vienu metu.

### Bitcoin veikimo sprendimai

- Kadangi Bitcoin yra **decentralizuota**, Bitcoin nėra reguliuojama (kaip paprastos valiutos).
- Paprastos valiutos turi centrinį procesorių transakcijų (pavyzdžiui, **bankas**), kuris registruoja visus atliekamus mokėjimus.
- Bitcoin transakcijos yra saugomos kiekviename kompiuteryje, kuris yra susijęs su Bitcoin. Būtent ši saugykla vadinama dižiąja knyga (**ledger**).
- Kiekvienoje transakcijoje, tinklas nuskaito siuntėjo ir gavėjo Bitcoin adresus, kiekį kiek perkelta Bitcoin ir užregistruoja į didžiosios knygos galą arba įrašą, pavadinimu - **Blockchain**. Blockchain yra atnaujinamas apie 100 kartų per dieną ir yra atnaujinamas kiekviename kompiuteryje, kuriame yra naudojama Bitcoin technologija.